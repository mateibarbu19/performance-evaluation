# Terms and domain

## **IS MOST RESEARCH WRONG?**

![Thumbnail of Veritasium [video](http://www.youtube.com/watch?v=42QuXLucH3Q).
In it's description we find a reference to metascience paper with 10k+
citations.](res/vertasium.jpg)

## What is Metascience?

:::::::::::::: {.columns}
::: {.column width="35%"}

![First page of John Ioannidis's paper that led to a broad investigation of
scientific research methodology.
@ioannidis2005most](res/Ioannidis_(2005).jpg)

:::
::: {.column width="65%"}

### Definition

**Metascience, the science of science**, uses rigorous methods to examine how
scientific practices influence the validity of scientific conclusions. It has
its roots in the *philosophy of science* and the *study of scientific methods*,
but is distinguished from the former by a reliance on *quantitative analysis*,
and from the latter by a broad focus on the general *factors* that contribute to
the **limitations and successes of research**. @schooler2014metascience

### At the end of the day {.example}

Meta-research involves taking a bird’s eye view of science. @ioannidis2015meta

:::
::::::::::::::


## Scientometrics - can you believe it?

### Definition

Scientometrics can be defined as the "quantitative study of science,
communication in science, and science policy" @scientometrics

### What does it all mean? {.example}

The intended effect [of rankings] is to create competition among institutions of
higher learning and research and thereby to increase their efficiency. The
rankings are supposed to identify excellence in these institutions and among
researchers. **Unintended effects** may be 'oversteering', either by forcing
less competitive **institutions to be closed down** or by **creating
oligopolies** whose once achieved position of supremacy cannot be challenged
anymore by competitors. @weingart2005impact

###  Where do we stand? {.alert}

The future of the higher education and research system rests on two pillars:
traditional **peer review** and **ranking**. @weingart2005impact

## Peer review - all shapes and sizes

### Definition

Peer review is designed to assess the validity, quality and often the
originality of articles for publication. Its ultimate purpose is to maintain the
integrity of science by filtering out invalid or poor quality articles. @whatis

### Types @ali2016peer

- *single blind*
    - the author is not aware of the reviewers' identities
    - reviewers may be unnecessarily critical while giving feedback
- **double blind**
    - the authors and reviewers are not aware of each other's identities
    - eliminates chances of bias
    - reviewers may still be able recognizeauthors through other markers such as
      writing style, subject matter and self-citation
- *open*
    - authors and reviewer are known to each other throughout the process

---

![Depiction of the paper-reviewer matching process (left) and decision-making
process (right) for submitted papers from the presented article
@soneji2022flawed](res/reviewing-process.png){
height=85% }

# Presented paper

## The security community needs

> "*Flawed, but like democracy we don’t have a better system*": The Experts’
> Insights on the Peer Review Process of Evaluating Security Papers
> @soneji2022flawed

Accepted in the 43rd IEEE Symposium on Security and Privacy, this paper presents
a exploratory qualitative study based on interviews with Program Committee
members (PCs) and Chairs ($n = 21$), being first of its kind.

The need for such a study is justified within these contextual problems:

- exponential increase in paper submissions to all venues
- delegation system of reviews and quantity and quality of them
- new submission model: rolling deadline 

Research questions:

1. How is the Science of Security currently served by the
    peer review process?
2. What are experts' opinions on current peer review mechanisms?


## Type of research - Qualitative

### Definition

Qualitative research seeks to understand - through person-to-person interviews -
how and why people think and behave the way that they do. [...] Take a **small
sample size**, spend time with the individuals, and learn about their
impressions and motivations. @qualitativeresearch

### Science of Security {.example}

However, we find that there is little clarity on what "scientific" means in the
context of computer security research, or consensus on what a "Science of
Security" should look like. @herley2017sok

### Human factors and data saturation {.alert}

Because security researchers study and **develop systems and solutions mainly
for human use**, qualitative human factors research in security is crucial.
[...] To obtain rigorous and exhaustive qualitative results, we conducted
interviews until new themes stopped emerging. @soneji2022flawed

## Interactions with the review system

## Evaluation Metrics

From the interviewees pe 

### No clear definition

As P19 puts it: Novelty is definitely subjective. This is something where
different reviewers will see different values out of a paper.

## Contributions

s-a materializat in Recommendations

# Conclusion

## How does everything relate?

The review system bla bla

## Take away

::: {.block}
### P01's take on writing a review

I feel that writing a review is just like writing a paper. In that, you
establish a position, you make some claims regarding that position, and then you
provide evidence to support that position. If any of these things are missing,
it is not a good review or a good paper.

:::

The authors have summarized their findings of PC members [recommendations for
authors](https://github.com/sonejiananta/Security-Review-Process/blob/main/RecommendationsToWriteBetterSecurityPapers.pdf)

```{=latex}
\center{\LARGE{\emph{The End.}}}
\center Made with \emoji{heart} and \LaTeX{}.
```

# Bibliography

## References {.allowframebreaks} 
